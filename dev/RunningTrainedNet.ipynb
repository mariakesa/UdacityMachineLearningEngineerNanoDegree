{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pl_bolts.models.rl import DQN\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_GYM_AVAILABLE' from 'pl_bolts.utils' (C:\\Users\\koester_lab\\anaconda3\\lib\\site-packages\\pl_bolts\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-95d158e2ce65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMultiStepBuffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_GYM_AVAILABLE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarnings\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarn_missing_pkg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_GYM_AVAILABLE' from 'pl_bolts.utils' (C:\\Users\\koester_lab\\anaconda3\\lib\\site-packages\\pl_bolts\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Deep Q Network\n",
    "\"\"\"\n",
    "import argparse\n",
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torch import optim as optim\n",
    "from torch.optim.optimizer import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from pl_bolts.datamodules.experience_source import Experience, ExperienceSourceDataset\n",
    "from pl_bolts.losses.rl import dqn_loss\n",
    "from pl_bolts.models.rl.common.agents import ValueAgent\n",
    "from pl_bolts.models.rl.common.gym_wrappers import make_environment\n",
    "from pl_bolts.models.rl.common.memory import MultiStepBuffer\n",
    "from pl_bolts.models.rl.common.networks import CNN\n",
    "from pl_bolts.utils import _GYM_AVAILABLE\n",
    "from pl_bolts.utils.warnings import warn_missing_pkg\n",
    "\n",
    "    from gym import Env\n",
    "else:  # pragma: no cover\n",
    "    warn_missing_pkg('gym')\n",
    "    Env = object\n",
    "\n",
    "\n",
    "class DQN(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Basic DQN Model\n",
    "\n",
    "    PyTorch Lightning implementation of `DQN <https://arxiv.org/abs/1312.5602>`_\n",
    "    Paper authors: Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves,\n",
    "    Ioannis Antonoglou, Daan Wierstra, Martin Riedmiller.\n",
    "    Model implemented by:\n",
    "\n",
    "        - `Donal Byrne <https://github.com/djbyrne>`\n",
    "\n",
    "    Example:\n",
    "        >>> from pl_bolts.models.rl.dqn_model import DQN\n",
    "        ...\n",
    "        >>> model = DQN(\"PongNoFrameskip-v4\")\n",
    "\n",
    "    Train::\n",
    "\n",
    "        trainer = Trainer()\n",
    "        trainer.fit(model)\n",
    "\n",
    "    Note:\n",
    "        This example is based on:\n",
    "        https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition/blob/master/Chapter06/02_dqn_pong.py\n",
    "\n",
    "    Note:\n",
    "        Currently only supports CPU and single GPU training with `distributed_backend=dp`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: str,\n",
    "        eps_start: float = 1.0,\n",
    "        eps_end: float = 0.02,\n",
    "        eps_last_frame: int = 150000,\n",
    "        sync_rate: int = 1000,\n",
    "        gamma: float = 0.99,\n",
    "        learning_rate: float = 1e-4,\n",
    "        batch_size: int = 32,\n",
    "        replay_size: int = 100000,\n",
    "        warm_start_size: int = 10000,\n",
    "        avg_reward_len: int = 100,\n",
    "        min_episode_reward: int = -21,\n",
    "        seed: int = 123,\n",
    "        batches_per_epoch: int = 1000,\n",
    "        n_steps: int = 1,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            env: gym environment tag\n",
    "            eps_start: starting value of epsilon for the epsilon-greedy exploration\n",
    "            eps_end: final value of epsilon for the epsilon-greedy exploration\n",
    "            eps_last_frame: the final frame in for the decrease of epsilon. At this frame espilon = eps_end\n",
    "            sync_rate: the number of iterations between syncing up the target network with the train network\n",
    "            gamma: discount factor\n",
    "            learning_rate: learning rate\n",
    "            batch_size: size of minibatch pulled from the DataLoader\n",
    "            replay_size: total capacity of the replay buffer\n",
    "            warm_start_size: how many random steps through the environment to be carried out at the start of\n",
    "                training to fill the buffer with a starting point\n",
    "            avg_reward_len: how many episodes to take into account when calculating the avg reward\n",
    "            min_episode_reward: the minimum score that can be achieved in an episode. Used for filling the avg buffer\n",
    "                before training begins\n",
    "            seed: seed value for all RNG used\n",
    "            batches_per_epoch: number of batches per epoch\n",
    "            n_steps: size of n step look ahead\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Environment\n",
    "        self.exp = None\n",
    "        self.env = self.make_environment(env, seed)\n",
    "        self.test_env = self.make_environment(env)\n",
    "\n",
    "        self.obs_shape = self.env.observation_space.shape\n",
    "        self.n_actions = self.env.action_space.n\n",
    "\n",
    "        # Model Attributes\n",
    "        self.buffer = None\n",
    "        self.dataset = None\n",
    "\n",
    "        self.net = None\n",
    "        self.target_net = None\n",
    "        self.build_networks()\n",
    "\n",
    "        self.agent = ValueAgent(\n",
    "            self.net,\n",
    "            self.n_actions,\n",
    "            eps_start=eps_start,\n",
    "            eps_end=eps_end,\n",
    "            eps_frames=eps_last_frame,\n",
    "        )\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.sync_rate = sync_rate\n",
    "        self.gamma = gamma\n",
    "        self.lr = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.replay_size = replay_size\n",
    "        self.warm_start_size = warm_start_size\n",
    "        self.batches_per_epoch = batches_per_epoch\n",
    "        self.n_steps = n_steps\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # Metrics\n",
    "        self.total_episode_steps = [0]\n",
    "        self.total_rewards = [0]\n",
    "        self.done_episodes = 0\n",
    "        self.total_steps = 0\n",
    "\n",
    "        # Average Rewards\n",
    "        self.avg_reward_len = avg_reward_len\n",
    "\n",
    "        for _ in range(avg_reward_len):\n",
    "            self.total_rewards.append(torch.tensor(min_episode_reward, device=self.device))\n",
    "\n",
    "        self.avg_rewards = float(np.mean(self.total_rewards[-self.avg_reward_len:]))\n",
    "\n",
    "        self.state = self.env.reset()\n",
    "\n",
    "    def run_n_episodes(self, env, n_epsiodes: int = 1, epsilon: float = 1.0) -> List[int]:\n",
    "        \"\"\"\n",
    "        Carries out N episodes of the environment with the current agent\n",
    "\n",
    "        Args:\n",
    "            env: environment to use, either train environment or test environment\n",
    "            n_epsiodes: number of episodes to run\n",
    "            epsilon: epsilon value for DQN agent\n",
    "        \"\"\"\n",
    "        total_rewards = []\n",
    "\n",
    "        for _ in range(n_epsiodes):\n",
    "            episode_state = env.reset()\n",
    "            done = False\n",
    "            episode_reward = 0\n",
    "\n",
    "            while not done:\n",
    "                self.agent.epsilon = epsilon\n",
    "                print(self.agent.net)\n",
    "                action = self.agent(episode_state, self.device)\n",
    "                next_state, reward, done, _ = env.step(action[0])\n",
    "                episode_state = next_state\n",
    "                episode_reward += reward\n",
    "\n",
    "            total_rewards.append(episode_reward)\n",
    "\n",
    "        return total_rewards\n",
    "\n",
    "    def populate(self, warm_start: int) -> None:\n",
    "        \"\"\"Populates the buffer with initial experience\"\"\"\n",
    "        if warm_start > 0:\n",
    "            self.state = self.env.reset()\n",
    "\n",
    "            for _ in range(warm_start):\n",
    "                self.agent.epsilon = 1.0\n",
    "                action = self.agent(self.state, self.device)\n",
    "                next_state, reward, done, _ = self.env.step(action[0])\n",
    "                exp = Experience(state=self.state, action=action[0], reward=reward, done=done, new_state=next_state)\n",
    "                self.buffer.append(exp)\n",
    "                self.state = next_state\n",
    "\n",
    "                if done:\n",
    "                    self.state = self.env.reset()\n",
    "\n",
    "    def build_networks(self) -> None:\n",
    "        \"\"\"Initializes the DQN train and target networks\"\"\"\n",
    "        self.net = CNN(self.obs_shape, self.n_actions)\n",
    "        self.target_net = CNN(self.obs_shape, self.n_actions)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Passes in a state x through the network and gets the q_values of each action as an output\n",
    "\n",
    "        Args:\n",
    "            x: environment state\n",
    "\n",
    "        Returns:\n",
    "            q values\n",
    "        \"\"\"\n",
    "        output = self.net(x)\n",
    "        return output\n",
    "\n",
    "    def train_batch(self, ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Contains the logic for generating a new batch of data to be passed to the DataLoader\n",
    "\n",
    "        Returns:\n",
    "            yields a Experience tuple containing the state, action, reward, done and next_state.\n",
    "        \"\"\"\n",
    "        episode_reward = 0\n",
    "        episode_steps = 0\n",
    "\n",
    "        while True:\n",
    "            self.total_steps += 1\n",
    "            action = self.agent(self.state, self.device)\n",
    "\n",
    "            next_state, r, is_done, _ = self.env.step(action[0])\n",
    "\n",
    "            episode_reward += r\n",
    "            episode_steps += 1\n",
    "\n",
    "            exp = Experience(state=self.state, action=action[0], reward=r, done=is_done, new_state=next_state)\n",
    "\n",
    "            self.agent.update_epsilon(self.global_step)\n",
    "            self.buffer.append(exp)\n",
    "            self.state = next_state\n",
    "\n",
    "            if is_done:\n",
    "                self.done_episodes += 1\n",
    "                self.total_rewards.append(episode_reward)\n",
    "                self.total_episode_steps.append(episode_steps)\n",
    "                self.avg_rewards = float(np.mean(self.total_rewards[-self.avg_reward_len:]))\n",
    "                self.state = self.env.reset()\n",
    "                episode_steps = 0\n",
    "                episode_reward = 0\n",
    "\n",
    "            states, actions, rewards, dones, new_states = self.buffer.sample(self.batch_size)\n",
    "\n",
    "            for idx, _ in enumerate(dones):\n",
    "                yield states[idx], actions[idx], rewards[idx], dones[idx], new_states[idx]\n",
    "\n",
    "            # Simulates epochs\n",
    "            if self.total_steps % self.batches_per_epoch == 0:\n",
    "                break\n",
    "\n",
    "    def training_step(self, batch: Tuple[torch.Tensor, torch.Tensor], _) -> OrderedDict:\n",
    "        \"\"\"\n",
    "        Carries out a single step through the environment to update the replay buffer.\n",
    "        Then calculates loss based on the minibatch recieved\n",
    "\n",
    "        Args:\n",
    "            batch: current mini batch of replay data\n",
    "            _: batch number, not used\n",
    "\n",
    "        Returns:\n",
    "            Training loss and log metrics\n",
    "        \"\"\"\n",
    "\n",
    "        # calculates training loss\n",
    "        loss = dqn_loss(batch, self.net, self.target_net)\n",
    "\n",
    "        if self.trainer.use_dp or self.trainer.use_ddp2:\n",
    "            loss = loss.unsqueeze(0)\n",
    "\n",
    "        # Soft update of target network\n",
    "        if self.global_step % self.sync_rate == 0:\n",
    "            self.target_net.load_state_dict(self.net.state_dict())\n",
    "\n",
    "        self.log_dict({\n",
    "            \"total_reward\": self.total_rewards[-1],\n",
    "            \"avg_reward\": self.avg_rewards,\n",
    "            \"train_loss\": loss,\n",
    "            \"episodes\": self.done_episodes,\n",
    "            \"episode_steps\": self.total_episode_steps[-1]\n",
    "        })\n",
    "\n",
    "        return OrderedDict({\n",
    "            \"loss\": loss,\n",
    "            \"avg_reward\": self.avg_rewards,\n",
    "        })\n",
    "\n",
    "    def test_step(self, *args, **kwargs) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Evaluate the agent for 10 episodes\"\"\"\n",
    "        test_reward = self.run_n_episodes(self.test_env, 1, 0)\n",
    "        avg_reward = sum(test_reward) / len(test_reward)\n",
    "        return {\"test_reward\": avg_reward}\n",
    "\n",
    "    def test_epoch_end(self, outputs) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Log the avg of the test results\"\"\"\n",
    "        rewards = [x[\"test_reward\"] for x in outputs]\n",
    "        avg_reward = sum(rewards) / len(rewards)\n",
    "        self.log(\"avg_test_reward\", avg_reward)\n",
    "        return {\"avg_test_reward\": avg_reward}\n",
    "\n",
    "    def configure_optimizers(self) -> List[Optimizer]:\n",
    "        \"\"\" Initialize Adam optimizer\"\"\"\n",
    "        optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        return [optimizer]\n",
    "\n",
    "    def _dataloader(self) -> DataLoader:\n",
    "        \"\"\"Initialize the Replay Buffer dataset used for retrieving experiences\"\"\"\n",
    "        self.buffer = MultiStepBuffer(self.replay_size, self.n_steps)\n",
    "        self.populate(self.warm_start_size)\n",
    "\n",
    "        self.dataset = ExperienceSourceDataset(self.train_batch)\n",
    "        return DataLoader(dataset=self.dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Get train loader\"\"\"\n",
    "        return self._dataloader()\n",
    "\n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        \"\"\"Get test loader\"\"\"\n",
    "        return self._dataloader()\n",
    "\n",
    "    @staticmethod\n",
    "    def make_environment(env_name: str, seed: Optional[int] = None) -> Env:\n",
    "        \"\"\"\n",
    "        Initialise gym  environment\n",
    "\n",
    "        Args:\n",
    "            env_name: environment name or tag\n",
    "            seed: value to seed the environment RNG for reproducibility\n",
    "\n",
    "        Returns:\n",
    "            gym environment\n",
    "        \"\"\"\n",
    "        env = make_environment(env_name)\n",
    "\n",
    "        if seed:\n",
    "            env.seed(seed)\n",
    "\n",
    "        return env\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(arg_parser: argparse.ArgumentParser, ) -> argparse.ArgumentParser:\n",
    "        \"\"\"\n",
    "        Adds arguments for DQN model\n",
    "\n",
    "        Note:\n",
    "            These params are fine tuned for Pong env.\n",
    "\n",
    "        Args:\n",
    "            arg_parser: parent parser\n",
    "        \"\"\"\n",
    "        arg_parser.add_argument(\n",
    "            \"--sync_rate\",\n",
    "            type=int,\n",
    "            default=1000,\n",
    "            help=\"how many frames do we update the target network\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--replay_size\",\n",
    "            type=int,\n",
    "            default=100000,\n",
    "            help=\"capacity of the replay buffer\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--warm_start_size\",\n",
    "            type=int,\n",
    "            default=10000,\n",
    "            help=\"how many samples do we use to fill our buffer at the start of training\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--eps_last_frame\",\n",
    "            type=int,\n",
    "            default=150000,\n",
    "            help=\"what frame should epsilon stop decaying\",\n",
    "        )\n",
    "        arg_parser.add_argument(\"--eps_start\", type=float, default=1.0, help=\"starting value of epsilon\")\n",
    "        arg_parser.add_argument(\"--eps_end\", type=float, default=0.02, help=\"final value of epsilon\")\n",
    "        arg_parser.add_argument(\"--batches_per_epoch\", type=int, default=10000, help=\"number of batches in an epoch\")\n",
    "        arg_parser.add_argument(\"--batch_size\", type=int, default=32, help=\"size of the batches\")\n",
    "        arg_parser.add_argument(\"--lr\", type=float, default=1e-4, help=\"learning rate\")\n",
    "\n",
    "        arg_parser.add_argument(\"--env\", type=str, required=True, help=\"gym environment tag\")\n",
    "        arg_parser.add_argument(\"--gamma\", type=float, default=0.99, help=\"discount factor\")\n",
    "\n",
    "        arg_parser.add_argument(\n",
    "            \"--avg_reward_len\",\n",
    "            type=int,\n",
    "            default=100,\n",
    "            help=\"how many episodes to include in avg reward\",\n",
    "        )\n",
    "        arg_parser.add_argument(\n",
    "            \"--n_steps\",\n",
    "            type=int,\n",
    "            default=1,\n",
    "            help=\"how many frames do we update the target network\",\n",
    "        )\n",
    "\n",
    "        return arg_parser\n",
    "\n",
    "\n",
    "def cli_main():\n",
    "    parser = argparse.ArgumentParser(add_help=False)\n",
    "\n",
    "    # trainer args\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "\n",
    "    # model args\n",
    "    parser = DQN.add_model_specific_args(parser)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    model = DQN(**args.__dict__)\n",
    "\n",
    "    # save checkpoints based on avg_reward\n",
    "    checkpoint_callback = ModelCheckpoint(save_top_k=1, monitor=\"avg_reward\", mode=\"max\", period=1, verbose=True)\n",
    "\n",
    "    seed_everything(123)\n",
    "    trainer = pl.Trainer.from_argparse_args(args, deterministic=True, checkpoint_callback=checkpoint_callback)\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cli_main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl_net=DQN(\"DemonAttack-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='C:/Users/koester_lab/Documents/Maria/UdacityMachineLearningEngineerNanoDegree/dqn_model.pth'\n",
    "rl_net.net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH='C:/Users/koester_lab/Documents/Maria/UdacityMachineLearningEngineerNanoDegree/dqn_target_model.pth'\n",
    "rl_net.target_net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (head): Sequential(\n",
      "    (0): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(rl_net.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv.0.weight tensor([[[[ 1.4061e-01,  1.5817e-01,  9.3741e-02,  ...,  2.0767e-01,\n",
      "            1.1412e-01,  1.7922e-01],\n",
      "          [-1.8039e-01, -1.1140e-01, -2.4167e-03,  ..., -6.0371e-02,\n",
      "           -3.6501e-03,  7.4139e-02],\n",
      "          [-5.6198e-02,  2.9089e-02, -1.0709e-01,  ...,  1.4791e-01,\n",
      "           -9.6401e-02, -4.5396e-02],\n",
      "          ...,\n",
      "          [-1.8010e-01, -9.6439e-03, -8.0007e-02,  ..., -1.0014e-01,\n",
      "           -9.6070e-02, -9.1505e-02],\n",
      "          [-4.3058e-02,  2.2279e-01,  1.7704e-01,  ...,  1.1755e-01,\n",
      "            5.3310e-02, -3.2649e-02],\n",
      "          [-9.0685e-02, -6.6909e-02, -3.1021e-02,  ...,  1.3404e-01,\n",
      "           -3.3881e-02, -4.1978e-02]],\n",
      "\n",
      "         [[-4.1514e-02,  3.0076e-02,  1.5313e-01,  ...,  3.4452e-02,\n",
      "            1.2762e-02,  3.8293e-02],\n",
      "          [-4.6260e-02, -7.4009e-02,  9.4509e-02,  ..., -8.5139e-02,\n",
      "           -1.5208e-01, -1.5362e-01],\n",
      "          [-3.4483e-02,  8.9416e-02,  7.7682e-02,  ...,  1.9344e-01,\n",
      "           -1.4048e-02, -9.8130e-02],\n",
      "          ...,\n",
      "          [-1.3674e-01,  2.4516e-01, -1.7455e-02,  ..., -2.5861e-02,\n",
      "           -4.5978e-02, -1.6369e-01],\n",
      "          [ 6.8107e-02,  3.9440e-01,  3.8777e-01,  ...,  8.0293e-02,\n",
      "           -7.6151e-04, -2.8302e-01],\n",
      "          [-1.4578e-01, -4.3480e-02, -1.8929e-01,  ...,  2.9894e-01,\n",
      "            3.8978e-02, -2.0691e-01]],\n",
      "\n",
      "         [[-6.3382e-02,  2.7515e-02,  7.7477e-02,  ..., -6.3801e-02,\n",
      "           -5.9886e-02, -1.0662e-01],\n",
      "          [-8.0254e-02, -1.0131e-01,  2.7776e-01,  ...,  1.6504e-02,\n",
      "           -7.7364e-02, -5.8577e-02],\n",
      "          [ 6.7782e-02,  1.7872e-01,  3.6710e-01,  ...,  1.0190e-01,\n",
      "            1.5152e-01, -9.3993e-02],\n",
      "          ...,\n",
      "          [-3.2440e-02,  4.5387e-01,  7.8837e-02,  ..., -2.4121e-01,\n",
      "           -2.0460e-01, -2.6614e-01],\n",
      "          [ 1.9947e-01,  7.5587e-01,  6.6836e-01,  ..., -2.2755e-01,\n",
      "           -1.1581e-01, -3.2893e-01],\n",
      "          [ 6.0634e-02,  3.4253e-01,  1.8328e-01,  ..., -2.4760e-01,\n",
      "           -1.8100e-01, -2.3447e-01]],\n",
      "\n",
      "         [[-1.4237e-02,  1.4479e-01,  2.7157e-01,  ..., -1.2115e-01,\n",
      "           -3.4732e-02,  2.4040e-02],\n",
      "          [ 2.8383e-02, -2.2866e-02,  2.0954e-01,  ..., -8.5192e-02,\n",
      "            9.0306e-02,  3.1703e-02],\n",
      "          [ 1.2170e-01, -8.7939e-02,  1.4687e-01,  ...,  2.1482e-01,\n",
      "            2.2671e-01,  5.1383e-02],\n",
      "          ...,\n",
      "          [ 2.5522e-01,  9.1556e-01,  5.2740e-01,  ..., -1.9809e-01,\n",
      "           -2.5617e-01, -3.2523e-01],\n",
      "          [ 4.8790e-01,  1.2007e+00,  1.1449e+00,  ..., -3.6421e-01,\n",
      "           -3.2317e-01, -3.2534e-01],\n",
      "          [ 7.2342e-02,  2.7798e-01,  2.7475e-01,  ..., -1.2337e-01,\n",
      "           -3.9304e-01, -4.8192e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4287e-03, -9.1825e-02,  6.7301e-02,  ..., -1.6088e-01,\n",
      "            1.8509e-02, -8.9943e-02],\n",
      "          [-3.7915e-02, -1.2844e-01,  2.7577e-02,  ..., -1.0710e-01,\n",
      "            1.6064e-02, -1.3036e-01],\n",
      "          [ 8.7313e-03, -2.7747e-02,  1.4952e-01,  ..., -7.0140e-02,\n",
      "           -5.2511e-02,  1.7778e-03],\n",
      "          ...,\n",
      "          [-3.2852e-03,  7.0703e-03,  1.5435e-02,  ..., -2.2884e-03,\n",
      "            3.5409e-03, -1.1349e-02],\n",
      "          [ 7.2494e-02, -4.4248e-02,  7.3689e-02,  ..., -4.2484e-02,\n",
      "            1.1279e-01,  1.0163e-01],\n",
      "          [ 5.4351e-02, -4.3054e-02,  9.6751e-02,  ..., -6.8822e-02,\n",
      "            5.7377e-02,  9.9495e-02]],\n",
      "\n",
      "         [[ 1.3504e-01, -6.7151e-03,  1.5061e-01,  ..., -8.4248e-02,\n",
      "           -5.4402e-02,  1.8392e-01],\n",
      "          [ 8.6407e-02,  3.5484e-03,  4.9155e-02,  ...,  1.8252e-02,\n",
      "           -2.9500e-03,  1.0649e-01],\n",
      "          [ 1.4200e-02, -4.2020e-02,  9.5548e-02,  ...,  3.2149e-02,\n",
      "           -3.9386e-03,  1.1039e-01],\n",
      "          ...,\n",
      "          [-8.8602e-03, -3.6088e-02,  9.4040e-03,  ..., -7.1113e-02,\n",
      "           -4.7758e-02, -3.0977e-02],\n",
      "          [ 1.8417e-02, -2.0200e-02, -2.5115e-02,  ..., -3.5029e-02,\n",
      "           -7.2634e-02,  2.8886e-02],\n",
      "          [ 3.0166e-02, -1.4886e-01, -1.1142e-01,  ..., -6.9456e-02,\n",
      "           -1.0925e-01,  1.8251e-02]],\n",
      "\n",
      "         [[ 6.9562e-02,  2.5594e-04,  2.0620e-01,  ..., -2.6759e-01,\n",
      "            2.5608e-02,  6.2687e-02],\n",
      "          [ 2.2358e-02, -4.2636e-02,  1.2585e-01,  ..., -2.9170e-01,\n",
      "           -3.9985e-02,  1.7090e-01],\n",
      "          [-2.4369e-01, -9.8028e-02,  5.9824e-02,  ..., -2.2637e-01,\n",
      "           -1.0935e-01, -3.7841e-03],\n",
      "          ...,\n",
      "          [ 1.3656e-01, -1.3668e-02,  9.9309e-02,  ...,  3.0071e-02,\n",
      "            4.6138e-02,  1.2403e-01],\n",
      "          [ 1.5936e-01,  3.6458e-02,  1.8552e-01,  ...,  1.7971e-02,\n",
      "           -1.0632e-02,  1.6016e-01],\n",
      "          [ 5.4495e-02, -3.2676e-02,  1.5894e-02,  ..., -1.2800e-01,\n",
      "           -5.8811e-03,  6.0028e-02]],\n",
      "\n",
      "         [[ 1.0621e-01, -2.7348e-04, -1.0669e-01,  ..., -8.4083e-01,\n",
      "           -5.7231e-01, -5.3974e-01],\n",
      "          [ 2.8374e-01,  1.2561e-01,  1.2370e-01,  ..., -1.1762e-01,\n",
      "           -1.5238e-01, -3.4316e-01],\n",
      "          [-5.5237e-02, -1.6067e-01,  7.7990e-02,  ...,  1.8999e-01,\n",
      "            1.0389e-01, -2.3354e-01],\n",
      "          ...,\n",
      "          [ 9.0147e-02,  2.0630e-01,  3.2160e-01,  ...,  2.6704e-01,\n",
      "            2.2181e-01,  2.4675e-01],\n",
      "          [ 1.1660e-01,  2.8283e-01,  2.5615e-01,  ...,  1.6842e-01,\n",
      "            1.4077e-01,  2.5548e-01],\n",
      "          [-5.9845e-02, -5.0141e-03,  2.8885e-01,  ...,  1.0582e-01,\n",
      "            1.8098e-01,  4.0327e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9310e-02,  2.1109e-02,  7.3538e-02,  ...,  6.5315e-02,\n",
      "           -2.2288e-01, -2.5558e-01],\n",
      "          [ 8.0991e-02, -2.9357e-02,  1.7590e-02,  ..., -1.2306e-01,\n",
      "           -4.0355e-01,  1.6388e-01],\n",
      "          [-1.9178e-01,  1.7739e-01,  2.0002e-02,  ..., -4.2381e-01,\n",
      "           -2.6528e-01,  1.4813e-01],\n",
      "          ...,\n",
      "          [ 1.0972e-01, -7.3972e-02,  8.2454e-02,  ..., -1.6861e-01,\n",
      "           -3.0555e-02, -3.9326e-01],\n",
      "          [ 3.1529e-01, -1.0189e-01, -1.7835e-02,  ...,  1.7382e-01,\n",
      "           -3.1463e-02, -2.5713e-01],\n",
      "          [ 7.9040e-03,  3.0830e-02, -2.4170e-01,  ...,  1.3689e-01,\n",
      "            1.0045e-01, -8.6029e-02]],\n",
      "\n",
      "         [[-1.9057e-01,  1.9677e-02,  8.7761e-02,  ...,  4.5481e-02,\n",
      "           -1.5090e-01,  1.1242e-01],\n",
      "          [-1.0414e-01,  1.4664e-01,  1.3262e-01,  ..., -3.1288e-01,\n",
      "           -1.5072e-01, -3.4914e-02],\n",
      "          [ 1.5808e-02,  2.1391e-01,  2.5091e-02,  ..., -1.7857e-01,\n",
      "           -1.3838e-01,  2.2401e-01],\n",
      "          ...,\n",
      "          [ 1.2315e-01, -3.0725e-01, -4.2806e-01,  ..., -1.7565e-01,\n",
      "            1.4221e-02, -2.2779e-01],\n",
      "          [-1.2701e-01, -2.7403e-01, -2.1938e-01,  ...,  2.5737e-01,\n",
      "           -1.5752e-01, -1.8004e-01],\n",
      "          [-2.8241e-01, -3.0555e-01, -1.2233e-01,  ...,  2.1394e-01,\n",
      "           -7.8279e-03, -2.1604e-01]],\n",
      "\n",
      "         [[ 1.0940e-01, -9.2211e-03, -8.3801e-02,  ..., -5.9441e-02,\n",
      "            7.5540e-02,  1.0851e-01],\n",
      "          [ 1.1412e-01,  1.5348e-01, -2.3106e-01,  ..., -9.3611e-02,\n",
      "            2.6573e-02,  5.5492e-02],\n",
      "          [ 4.6245e-02,  7.7428e-02, -5.0757e-01,  ..., -1.5599e-01,\n",
      "            8.4933e-02,  3.7362e-01],\n",
      "          ...,\n",
      "          [-2.5500e-01, -5.5072e-02,  1.0571e-01,  ..., -3.7525e-01,\n",
      "           -1.8137e-01, -2.1490e-01],\n",
      "          [-1.3991e-01,  2.0854e-01,  4.6361e-01,  ...,  4.7101e-02,\n",
      "           -7.6227e-02, -5.4622e-01],\n",
      "          [-6.5862e-02, -2.6423e-02,  4.1914e-01,  ...,  2.2704e-01,\n",
      "           -6.0858e-02, -2.1483e-01]],\n",
      "\n",
      "         [[ 1.5332e-01,  3.9672e-01,  2.7189e-01,  ...,  5.1275e-02,\n",
      "           -2.4322e-01, -5.6934e-01],\n",
      "          [ 3.4411e-01,  1.8350e-01,  8.2867e-02,  ..., -5.5211e-01,\n",
      "           -3.8376e-01, -8.1297e-01],\n",
      "          [-6.8665e-03,  3.5881e-02, -6.0296e-01,  ..., -1.1259e+00,\n",
      "           -1.9716e-01, -7.1378e-01],\n",
      "          ...,\n",
      "          [-1.3671e-01,  9.4926e-02,  5.6726e-01,  ...,  4.9790e-01,\n",
      "            3.0868e-01, -3.9130e-01],\n",
      "          [ 2.4691e-01,  3.3735e-01,  9.2643e-01,  ...,  7.8372e-01,\n",
      "            4.3146e-01, -3.2384e-01],\n",
      "          [ 1.0377e-01,  2.6677e-01,  7.0668e-01,  ...,  6.9145e-01,\n",
      "            1.8006e-02, -5.3854e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.5530e-01, -6.1036e-02, -1.2742e-01,  ..., -5.7505e-03,\n",
      "            1.2595e-01, -3.9349e-02],\n",
      "          [-1.4772e-01, -6.4142e-01, -3.1510e-01,  ...,  5.6427e-02,\n",
      "           -7.0233e-03, -1.0590e-01],\n",
      "          [-1.4650e-01, -1.1070e+00, -7.2544e-02,  ...,  1.6799e-01,\n",
      "            9.2251e-02, -1.2715e-01],\n",
      "          ...,\n",
      "          [-3.2521e-01, -2.8236e-01, -2.8311e-02,  ...,  4.2266e-02,\n",
      "           -6.0731e-02, -4.0583e-01],\n",
      "          [-1.5511e-01, -2.1413e-01,  4.2892e-02,  ...,  1.5492e-02,\n",
      "           -1.7768e-01, -2.3640e-01],\n",
      "          [-1.4372e-01, -1.3298e-02, -1.2115e-01,  ...,  1.3980e-01,\n",
      "           -3.3101e-01, -5.6085e-02]],\n",
      "\n",
      "         [[-3.5982e-01, -1.2282e-02,  2.8436e-01,  ...,  1.9228e-02,\n",
      "           -2.3529e-01, -1.3917e-01],\n",
      "          [-2.8204e-01,  7.3458e-02,  2.1432e-01,  ..., -2.7522e-01,\n",
      "           -5.1268e-01, -2.1612e-01],\n",
      "          [-2.1703e-01,  6.0831e-02,  2.5545e-01,  ..., -3.5851e-01,\n",
      "           -4.8483e-01, -1.7199e-01],\n",
      "          ...,\n",
      "          [-2.6198e-02, -2.6094e-01, -5.8809e-01,  ...,  1.7106e-02,\n",
      "            2.2806e-01,  5.4295e-02],\n",
      "          [ 7.2640e-02, -1.9560e-01, -8.4932e-01,  ...,  1.9870e-01,\n",
      "            1.5214e-01,  5.4187e-03],\n",
      "          [ 1.5040e-01, -5.9501e-02, -2.6627e-01,  ...,  2.4325e-01,\n",
      "            2.5953e-01, -8.0726e-03]],\n",
      "\n",
      "         [[-2.5449e-01,  4.4305e-02,  7.9969e-02,  ..., -1.7214e-01,\n",
      "           -3.9679e-01, -4.5286e-01],\n",
      "          [-1.3469e-01, -3.2980e-02,  1.4390e-01,  ..., -2.6608e-01,\n",
      "           -1.0933e+00, -7.0419e-01],\n",
      "          [ 3.7242e-03, -9.9494e-03,  1.2045e-01,  ..., -2.1244e-01,\n",
      "           -1.2755e+00, -9.9422e-01],\n",
      "          ...,\n",
      "          [-3.8288e-02, -6.8712e-02,  8.1017e-02,  ...,  2.9803e-01,\n",
      "           -5.2704e-01, -1.4528e+00],\n",
      "          [-1.3360e-01, -7.4013e-02,  2.6999e-01,  ...,  1.6398e-01,\n",
      "           -2.0563e-01, -1.0614e+00],\n",
      "          [-1.3936e-01, -7.7198e-02,  1.2984e-01,  ..., -1.9438e-01,\n",
      "           -6.1749e-02, -8.3475e-01]],\n",
      "\n",
      "         [[-9.6963e-02, -1.1225e-02, -1.2088e-01,  ..., -3.1579e-01,\n",
      "           -8.8500e-02,  8.7582e-02],\n",
      "          [-1.2174e-02,  8.4661e-02, -8.2545e-02,  ..., -1.8510e-01,\n",
      "            2.2184e-02,  1.8893e-01],\n",
      "          [ 2.0514e-01,  2.0026e-01, -1.3955e-01,  ..., -2.3209e-01,\n",
      "            6.7667e-02,  6.9474e-02],\n",
      "          ...,\n",
      "          [ 6.7036e-02,  1.0259e-01,  2.0794e-01,  ...,  1.1925e-02,\n",
      "            1.8485e-01,  3.0625e-01],\n",
      "          [-7.5742e-02, -1.1261e-02,  2.7017e-01,  ...,  8.8477e-02,\n",
      "           -5.4750e-03,  1.5832e-01],\n",
      "          [-1.0398e-01,  3.4238e-02,  1.2450e-01,  ...,  9.6248e-03,\n",
      "            1.8325e-01,  7.2852e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.1669e-02,  2.5129e-02,  6.2485e-03,  ...,  7.5069e-02,\n",
      "            6.3448e-02, -1.1377e-02],\n",
      "          [ 5.7132e-04, -2.4490e-02, -3.7869e-02,  ...,  3.1302e-02,\n",
      "            4.6452e-02, -5.0813e-02],\n",
      "          [-2.1631e-02,  1.2028e-01, -8.0845e-02,  ...,  1.5813e-01,\n",
      "           -5.8976e-02, -4.3038e-02],\n",
      "          ...,\n",
      "          [-8.0974e-02,  4.2571e-02,  1.2215e-01,  ..., -2.5943e-02,\n",
      "           -8.0830e-02,  1.0707e-01],\n",
      "          [-8.4615e-02,  9.0924e-03,  1.3977e-01,  ..., -1.5130e-01,\n",
      "            1.4243e-01,  5.8735e-02],\n",
      "          [-9.3559e-02, -8.2432e-02,  1.7747e-01,  ..., -1.9431e-01,\n",
      "            2.9730e-02,  8.1843e-02]],\n",
      "\n",
      "         [[-1.6107e-01,  1.6292e-01,  1.8594e-01,  ..., -1.0098e-01,\n",
      "           -1.6628e-01,  1.8099e-01],\n",
      "          [-3.2799e-02,  9.5962e-02,  9.9640e-02,  ..., -1.1497e-01,\n",
      "           -3.7183e-02,  1.6112e-01],\n",
      "          [-1.2655e-02,  1.4190e-01, -4.7541e-04,  ..., -4.1397e-02,\n",
      "            1.4821e-03,  2.8646e-02],\n",
      "          ...,\n",
      "          [ 2.1908e-01, -3.6641e-02, -2.1359e-01,  ...,  3.2755e-01,\n",
      "            6.3628e-02, -2.1955e-01],\n",
      "          [ 1.8650e-01, -1.1591e-01, -1.7326e-01,  ...,  2.2320e-01,\n",
      "            1.5495e-01, -2.2604e-01],\n",
      "          [ 8.3883e-02, -1.0302e-01, -1.5230e-01,  ...,  1.7440e-01,\n",
      "            3.3359e-02, -2.4134e-01]],\n",
      "\n",
      "         [[-5.9070e-01,  3.6034e-02,  3.0560e-01,  ..., -1.8998e-01,\n",
      "           -1.1704e-01, -1.4948e-03],\n",
      "          [-5.0571e-01, -3.4006e-01,  2.0262e-02,  ..., -9.6303e-02,\n",
      "           -1.9560e-01, -2.1017e-03],\n",
      "          [-2.2194e-01, -4.1154e-01, -2.0455e-01,  ...,  1.5353e-01,\n",
      "           -2.9487e-01, -1.5602e-01],\n",
      "          ...,\n",
      "          [ 4.9298e-01, -3.9641e-02, -6.6295e-01,  ...,  7.5959e-01,\n",
      "            7.8329e-02, -5.9596e-01],\n",
      "          [ 4.5902e-01,  4.3533e-02, -5.2209e-01,  ...,  6.5317e-01,\n",
      "            2.6061e-01, -5.9010e-01],\n",
      "          [ 2.6286e-01,  6.0802e-02, -5.1092e-01,  ...,  4.8714e-01,\n",
      "            1.8520e-01, -4.5930e-01]],\n",
      "\n",
      "         [[-7.0180e-02,  8.3409e-02,  1.5843e-01,  ..., -1.5896e-01,\n",
      "           -6.2108e-02, -4.7509e-02],\n",
      "          [-8.5399e-02, -1.1428e-01,  1.3207e-01,  ..., -3.0645e-02,\n",
      "           -1.6718e-01,  1.1773e-01],\n",
      "          [-7.3064e-02, -4.0454e-02, -9.1945e-02,  ..., -1.1394e-01,\n",
      "           -7.6367e-02, -5.6865e-03],\n",
      "          ...,\n",
      "          [ 2.1198e-01,  3.0659e-02, -6.1986e-02,  ...,  2.8498e-01,\n",
      "            1.6253e-01, -1.7873e-01],\n",
      "          [ 9.3271e-02,  1.6851e-01,  5.0410e-02,  ...,  2.9022e-01,\n",
      "            2.4469e-01, -1.9030e-01],\n",
      "          [ 8.7522e-02,  1.6582e-01,  4.7419e-02,  ...,  1.7388e-01,\n",
      "            7.1665e-02, -8.5798e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.1579e-02, -1.1793e-01, -1.4366e-01,  ...,  1.4748e-01,\n",
      "            5.2166e-02,  2.5077e-01],\n",
      "          [-1.0725e-01, -1.4784e-01, -1.0340e-01,  ...,  1.9513e-01,\n",
      "            3.9650e-01,  2.4990e-01],\n",
      "          [-1.3609e-01, -9.4728e-02, -1.6100e-01,  ..., -1.6368e-02,\n",
      "            2.1937e-01,  2.7799e-01],\n",
      "          ...,\n",
      "          [-2.1195e-01,  3.7904e-02, -2.7397e-04,  ..., -1.3628e-02,\n",
      "           -1.8743e-01, -2.3437e-01],\n",
      "          [ 1.7162e-01, -1.4852e-01, -6.4545e-02,  ..., -1.3512e-01,\n",
      "           -4.3030e-02, -2.7284e-01],\n",
      "          [ 3.2653e-01,  5.6162e-04,  1.4170e-02,  ..., -7.0577e-03,\n",
      "            4.3012e-02, -1.1775e-01]],\n",
      "\n",
      "         [[-4.8678e-01, -3.0192e-01, -4.1849e-02,  ...,  3.6655e-01,\n",
      "            3.9299e-01,  3.3835e-01],\n",
      "          [-3.4302e-01, -2.8021e-01, -1.4291e-01,  ...,  4.7029e-01,\n",
      "            6.3862e-01,  3.1780e-01],\n",
      "          [-3.3390e-01, -2.4217e-01, -1.2034e-01,  ...,  4.5574e-01,\n",
      "            5.7019e-01,  3.4713e-01],\n",
      "          ...,\n",
      "          [ 1.4148e-01, -8.4685e-02, -5.0940e-02,  ..., -1.1936e-01,\n",
      "           -1.4847e-01, -3.1096e-02],\n",
      "          [ 3.8522e-01, -6.0398e-02, -1.6460e-01,  ..., -6.1705e-01,\n",
      "           -4.6460e-01, -6.2300e-01],\n",
      "          [ 2.0868e-01,  2.9037e-02, -5.5280e-02,  ..., -3.9201e-01,\n",
      "           -4.4536e-01, -3.8463e-01]],\n",
      "\n",
      "         [[-1.6938e-01, -1.0211e-01, -4.7706e-02,  ...,  1.1232e-01,\n",
      "            2.8060e-01,  1.8956e-01],\n",
      "          [-3.3902e-01, -3.0023e-01, -3.2225e-01,  ...,  3.6637e-01,\n",
      "            2.3528e-01,  2.3815e-01],\n",
      "          [-1.2841e-01, -1.3315e-01, -1.1043e-01,  ...,  7.1014e-02,\n",
      "            3.4495e-01,  9.1713e-02],\n",
      "          ...,\n",
      "          [ 7.6656e-02,  4.2128e-01,  3.8062e-01,  ..., -2.0732e-01,\n",
      "           -3.6303e-01, -3.2607e-01],\n",
      "          [-9.3380e-03,  2.7111e-01, -1.2849e-02,  ..., -2.6348e-02,\n",
      "           -3.9747e-01,  1.5123e-02],\n",
      "          [ 1.3744e-01, -2.9042e-02,  6.4967e-03,  ...,  2.7302e-02,\n",
      "           -3.5782e-01, -2.7115e-02]],\n",
      "\n",
      "         [[-4.0100e-01,  1.4225e-01,  3.9147e-01,  ...,  3.3837e-01,\n",
      "            1.6673e-01, -1.7049e-01],\n",
      "          [-3.1371e-01,  8.4820e-03,  2.7106e-01,  ...,  4.7113e-01,\n",
      "            3.4643e-01,  4.9500e-01],\n",
      "          [-2.3123e-01, -9.5745e-02, -1.3788e-02,  ...,  1.0638e-01,\n",
      "            2.1221e-01,  3.8631e-01],\n",
      "          ...,\n",
      "          [ 2.5439e-01,  3.2680e-02,  3.8990e-02,  ..., -2.4626e-01,\n",
      "           -5.2970e-01, -5.6095e-01],\n",
      "          [-1.4357e-01,  2.7420e-01,  2.9781e-01,  ...,  8.6987e-02,\n",
      "           -7.1614e-02, -4.8695e-01],\n",
      "          [ 1.4131e-01,  2.2824e-01,  4.4658e-01,  ..., -1.5658e-02,\n",
      "           -2.2283e-01, -7.2276e-01]]]])\n",
      "conv.0.bias tensor([-5.7932e-04, -1.4366e-03,  7.2471e-03, -3.3559e-01, -8.8109e-02,\n",
      "         1.3407e-03, -7.8664e-02, -7.3678e-02, -5.4779e-02,  2.5211e-02,\n",
      "        -2.3796e-03,  4.3536e-01, -1.1909e-02, -2.3705e-02, -1.1613e-03,\n",
      "         2.1704e-01, -5.8848e-01, -6.9798e-03, -2.4655e-03, -3.7255e-02,\n",
      "         4.5840e-04, -1.7590e-03, -1.8399e-02, -8.2136e-04, -1.6475e-03,\n",
      "         1.0334e-01, -2.3076e-03, -4.5723e-02,  5.8726e-02,  1.9013e-01,\n",
      "        -2.8202e-02, -7.6339e-04])\n",
      "conv.2.weight tensor([[[[-8.3955e-04,  1.5728e-02, -2.7342e-02, -2.5485e-01],\n",
      "          [-2.3490e-01, -6.0228e-02, -4.2779e-01, -3.2600e-01],\n",
      "          [-2.9399e-01, -1.2178e-01, -2.0771e-02, -2.6057e-01],\n",
      "          [-7.8563e-02, -9.2599e-02,  1.0162e-01,  1.5284e-02]],\n",
      "\n",
      "         [[-9.5309e-02, -8.7813e-02, -4.6979e-01, -7.0092e-02],\n",
      "          [-7.3281e-02, -1.6941e-01, -1.4597e-01, -6.3254e-02],\n",
      "          [-2.0964e-01, -1.4582e-01, -2.0719e-01, -3.3234e-01],\n",
      "          [ 6.7670e-02,  1.2694e-01,  1.5479e-01,  1.2630e-01]],\n",
      "\n",
      "         [[ 3.5798e-01,  1.9763e-01,  6.1305e-02, -7.0368e-02],\n",
      "          [ 3.5145e-03, -1.1308e-01, -8.1447e-02, -7.5094e-02],\n",
      "          [-1.9413e-01,  1.4608e-01,  2.3032e-01,  4.4200e-03],\n",
      "          [ 2.9253e-01,  3.3927e-02,  1.5188e-01,  9.6960e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0965e-01,  1.7585e-01,  8.1333e-02,  9.4962e-02],\n",
      "          [ 1.1124e-01,  1.1672e-01,  1.0813e-01,  3.8260e-02],\n",
      "          [ 5.4018e-02,  1.4332e-01,  6.7316e-02,  1.3848e-01],\n",
      "          [ 4.5146e-02,  5.1899e-03,  7.0584e-02,  6.6323e-02]],\n",
      "\n",
      "         [[-4.1640e-01,  8.4875e-02, -3.9842e-01, -1.8450e-01],\n",
      "          [-7.1143e-03,  1.1799e-01, -4.0947e-01,  2.0947e-02],\n",
      "          [-2.9701e-01,  1.1233e-02, -7.9107e-02, -2.9196e-01],\n",
      "          [-2.0615e-01,  1.1728e-01, -1.8407e-01, -4.9355e-02]],\n",
      "\n",
      "         [[-8.6601e-02,  4.7847e-02, -1.2897e-01,  1.8887e-01],\n",
      "          [ 2.9780e-01,  2.2608e-01, -4.2976e-03,  1.9248e-01],\n",
      "          [ 3.2938e-01,  3.5448e-01,  3.0301e-01,  2.4071e-01],\n",
      "          [ 2.1315e-01,  2.3476e-01,  2.2336e-01,  5.1884e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6078e-02, -6.6042e-03,  2.2198e-02, -4.0545e-03],\n",
      "          [ 2.4263e-02, -1.6261e-01,  1.3442e-01,  1.6185e-01],\n",
      "          [-2.4129e-01, -4.7023e-02, -1.4468e-02, -8.2633e-02],\n",
      "          [-1.5622e-01,  5.5207e-02,  2.6437e-01,  5.7779e-02]],\n",
      "\n",
      "         [[ 1.0056e-01,  9.3186e-02,  1.4593e-01,  6.2985e-02],\n",
      "          [-2.6615e-02,  1.3864e-02, -1.0505e-02,  1.7447e-01],\n",
      "          [ 5.7849e-02,  9.4806e-02,  2.4747e-01,  1.3578e-01],\n",
      "          [ 9.0058e-02,  1.3432e-01,  8.7745e-02,  4.2415e-02]],\n",
      "\n",
      "         [[-4.5217e-02, -4.2590e-02, -1.1930e-01,  7.1739e-02],\n",
      "          [ 1.5345e-01,  1.1807e-01,  5.7851e-02,  1.5326e-01],\n",
      "          [ 2.0906e-01,  1.8098e-01,  2.8258e-03,  7.1231e-02],\n",
      "          [ 1.4536e-01,  5.3066e-02, -1.3890e-02, -2.7260e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8759e-02,  8.7339e-02,  5.1568e-02,  1.2605e-01],\n",
      "          [-2.5555e-02, -2.5471e-01, -2.3828e-01, -1.6919e-01],\n",
      "          [ 2.9283e-04, -1.8273e-01, -2.4366e-01, -1.1292e-01],\n",
      "          [-1.8190e-02, -1.9806e-01, -3.4075e-01, -9.2251e-02]],\n",
      "\n",
      "         [[-4.5979e-04, -1.3148e-01,  1.2645e-01, -1.2723e-01],\n",
      "          [-1.7450e-01, -5.3357e-01, -3.1809e-01, -5.7610e-01],\n",
      "          [-3.3269e-01, -5.2784e-01, -4.6474e-01, -6.1333e-01],\n",
      "          [-2.4194e-01, -4.4825e-01, -3.3794e-01, -2.5955e-01]],\n",
      "\n",
      "         [[-3.0409e-02, -7.1209e-02,  1.5649e-01, -4.8564e-02],\n",
      "          [-1.1435e-01, -4.3684e-02,  3.4457e-03,  1.3234e-02],\n",
      "          [ 2.5723e-02,  1.3201e-02, -1.2896e-01,  1.0063e-01],\n",
      "          [ 9.8394e-02,  3.6775e-02,  1.1413e-01,  2.0181e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2393e-01, -3.7158e-02,  7.3433e-02, -5.4119e-02],\n",
      "          [ 5.5832e-02, -1.0446e-01,  8.5014e-02, -1.4391e-01],\n",
      "          [-1.3122e-01,  3.5226e-02, -2.4421e-01,  5.4485e-02],\n",
      "          [ 1.0950e-01, -5.6754e-02,  1.3525e-01,  1.6929e-01]],\n",
      "\n",
      "         [[-6.8151e-02,  2.9736e-02,  3.8287e-02, -2.2295e-01],\n",
      "          [ 7.1317e-02,  1.1613e-01,  9.9059e-02, -2.4897e-01],\n",
      "          [-3.6337e-01, -2.1555e-01, -2.1619e-01, -2.2869e-01],\n",
      "          [-2.2061e-02, -3.6404e-02, -7.7725e-02, -2.2724e-01]],\n",
      "\n",
      "         [[ 9.2997e-02,  1.4608e-01,  3.5895e-01, -8.0557e-02],\n",
      "          [ 1.1507e-01,  3.1896e-01,  3.0886e-01,  3.6757e-02],\n",
      "          [ 5.1640e-01,  2.0878e-01,  4.2202e-01,  2.9007e-01],\n",
      "          [ 1.1087e-01,  2.1289e-01,  2.5443e-01,  1.9850e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.2288e-01,  1.0112e-01,  1.4573e-02,  1.4744e-01],\n",
      "          [ 1.9730e-01,  1.2599e-01,  1.4687e-02,  8.2793e-02],\n",
      "          [ 9.7730e-02,  1.7969e-01, -1.4708e-02,  6.7310e-02],\n",
      "          [ 6.9127e-02,  1.3169e-01, -1.1836e-01,  2.1099e-03]],\n",
      "\n",
      "         [[ 6.5341e-02,  1.6433e-01,  1.7245e-01, -7.4647e-02],\n",
      "          [ 3.3187e-01,  1.3440e-01,  3.3260e-01,  1.0842e-02],\n",
      "          [-4.2711e-01,  2.2420e-01,  1.3273e-01,  1.5403e-01],\n",
      "          [ 5.1287e-02,  2.8561e-01,  1.4168e-01,  2.7429e-02]],\n",
      "\n",
      "         [[ 2.4921e-02,  2.0291e-01,  9.0640e-04,  6.5299e-02],\n",
      "          [ 1.8469e-01,  8.8180e-02,  1.8434e-01,  8.4112e-02],\n",
      "          [ 2.1019e-01,  1.4011e-01,  3.2110e-01,  2.5327e-01],\n",
      "          [-3.4158e-01,  3.7449e-01,  1.5884e-01,  2.9223e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.0620e-02,  4.6650e-02,  5.2898e-02,  1.6009e-01],\n",
      "          [ 5.4151e-02, -9.9161e-03, -1.0337e-01,  5.5062e-02],\n",
      "          [-7.1443e-02,  7.7568e-02,  1.0478e-01, -3.2258e-02],\n",
      "          [ 2.8940e-02,  1.6258e-01,  1.7699e-01, -4.9707e-02]],\n",
      "\n",
      "         [[ 1.0846e-02,  4.3629e-02,  1.3721e-01,  1.9287e-03],\n",
      "          [ 1.2739e-01, -3.2785e-02,  1.3343e-01,  1.5947e-01],\n",
      "          [ 1.1444e-01,  1.2342e-02,  6.8574e-02,  1.2900e-01],\n",
      "          [-5.7154e-02, -2.7797e-02,  3.3168e-02,  7.4597e-02]],\n",
      "\n",
      "         [[-8.2214e-02, -3.7637e-01,  3.4264e-02, -1.6411e-01],\n",
      "          [ 3.0200e-01,  1.2492e-01,  1.3874e-01, -1.1808e-01],\n",
      "          [-7.2909e-03, -3.5105e-02, -2.7129e-02, -1.0402e-01],\n",
      "          [-1.1698e-01, -2.1565e-01, -1.6221e-01, -3.5505e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3312e-02, -1.0377e-01,  5.6692e-02,  1.0240e-01],\n",
      "          [-8.1935e-02,  1.2789e-03, -2.5405e-02,  4.1210e-02],\n",
      "          [-1.8704e-02, -2.2197e-01, -2.6118e-01, -1.7842e-01],\n",
      "          [-4.1295e-02, -2.0703e-01, -2.9351e-01, -1.9767e-01]],\n",
      "\n",
      "         [[ 1.0409e-01, -6.5969e-02,  1.4588e-01, -7.3572e-02],\n",
      "          [-9.1164e-02, -4.9100e-01,  5.2762e-02, -1.2481e-01],\n",
      "          [-2.2022e-02, -3.2977e-01,  5.6930e-02,  2.6335e-01],\n",
      "          [-6.0108e-02,  2.9063e-01, -4.7566e-02,  2.9218e-01]],\n",
      "\n",
      "         [[-1.0595e-01, -2.1040e-01,  2.3381e-02,  8.9167e-02],\n",
      "          [-1.7184e-02,  4.8695e-02,  3.8231e-02, -6.8413e-02],\n",
      "          [ 4.4384e-02,  1.0056e-01, -7.4378e-02, -2.4160e-01],\n",
      "          [ 5.7293e-02,  1.7442e-01, -1.0248e-01, -1.8318e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3065e-02, -2.0425e-02, -2.9982e-01, -1.6407e-02],\n",
      "          [ 1.2406e-01,  2.5809e-02, -3.7340e-01,  4.4729e-02],\n",
      "          [-8.2033e-03, -9.4305e-02, -2.1279e-01, -1.5664e-01],\n",
      "          [ 1.2564e-01,  1.4026e-01, -3.6497e-02,  5.3460e-03]],\n",
      "\n",
      "         [[-3.5011e-01,  2.6226e-03, -1.1349e-01, -3.5935e-01],\n",
      "          [-3.2770e-01, -7.1365e-02, -2.2282e-01, -8.9410e-02],\n",
      "          [-2.6297e-01,  1.6088e-02, -2.6116e-01, -1.6321e-01],\n",
      "          [-2.3688e-01, -4.9185e-02, -2.1539e-01, -6.9549e-02]],\n",
      "\n",
      "         [[-8.6492e-02,  1.6703e-01,  1.4833e-01,  2.2387e-01],\n",
      "          [-6.1848e-02,  3.3933e-01,  2.5266e-01,  1.5243e-01],\n",
      "          [ 1.5620e-02,  2.3016e-01,  3.1082e-01, -1.2888e-01],\n",
      "          [ 8.9513e-02,  2.0020e-01,  3.2370e-01,  1.2009e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.8244e-03,  1.0393e-01,  9.6379e-02,  3.9268e-02],\n",
      "          [-4.3000e-02,  8.4195e-02, -1.6220e-02,  1.5316e-02],\n",
      "          [ 4.3620e-02,  1.9122e-02,  1.1152e-02, -2.5978e-02],\n",
      "          [ 1.7981e-02, -4.2454e-02, -9.7709e-02,  3.0457e-02]],\n",
      "\n",
      "         [[-5.1771e-02, -2.9966e-01,  1.9692e-01,  1.3707e-01],\n",
      "          [ 3.0905e-01, -6.9165e-02,  1.7093e-02,  1.8123e-01],\n",
      "          [ 1.4170e-01, -1.3736e-02, -1.5659e-02, -6.2554e-02],\n",
      "          [ 3.5970e-01, -1.3917e-01,  1.4525e-01,  2.7635e-01]],\n",
      "\n",
      "         [[ 1.3896e-01,  8.0558e-02,  1.5316e-02,  1.1632e-01],\n",
      "          [ 2.2719e-01, -6.2656e-02, -7.5826e-02,  1.5015e-01],\n",
      "          [ 7.7476e-02,  4.1032e-01,  5.4984e-02, -2.3150e-02],\n",
      "          [ 2.1865e-01,  1.9903e-01,  2.3779e-01, -3.2284e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7227e-01, -1.5556e-02,  2.2534e-02, -1.7472e-02],\n",
      "          [ 1.9867e-01, -9.7476e-02,  1.2266e-01, -2.2110e-02],\n",
      "          [-3.1983e-02,  2.2326e-01, -2.6135e-01, -4.1043e-01],\n",
      "          [-1.9222e-02, -6.4014e-02,  5.8142e-02, -7.1677e-01]],\n",
      "\n",
      "         [[-1.7666e-02,  6.6883e-02,  1.3465e-01,  1.0522e-01],\n",
      "          [ 1.9052e-01,  2.6782e-01,  3.6762e-01,  3.6095e-01],\n",
      "          [ 5.8284e-02, -4.7099e-02, -7.2406e-02, -1.5314e-01],\n",
      "          [-4.4127e-02, -2.8871e-01, -1.0840e-01, -2.9141e-01]],\n",
      "\n",
      "         [[ 8.0966e-02,  3.2456e-02,  1.7891e-01,  2.3693e-01],\n",
      "          [ 1.2678e-01,  2.6376e-01,  5.1842e-01,  3.8487e-01],\n",
      "          [ 3.5948e-01, -5.8071e-03, -1.2349e-01,  9.8037e-02],\n",
      "          [ 5.3140e-02,  2.4562e-01, -6.0023e-03, -2.8016e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.6761e-02,  8.1801e-02,  4.5441e-02, -2.9074e-02],\n",
      "          [ 9.6621e-02,  1.5136e-01,  1.0333e-01,  4.8584e-02],\n",
      "          [-4.5338e-02, -1.2149e-02,  2.0587e-02,  6.2513e-02],\n",
      "          [-5.6601e-02,  5.3968e-02,  7.0498e-02,  1.2249e-02]],\n",
      "\n",
      "         [[ 1.4651e-02,  1.4477e-01,  1.3887e-01,  2.9971e-01],\n",
      "          [ 1.0975e-02, -4.2311e-02,  3.0356e-01,  1.1672e-01],\n",
      "          [-1.6292e-01, -1.6463e-01, -4.4355e-01, -4.5691e-01],\n",
      "          [-2.2453e-01,  1.3835e-01, -7.6450e-01, -3.0400e-01]],\n",
      "\n",
      "         [[ 9.1703e-02,  1.7113e-01,  2.2612e-01,  2.2862e-01],\n",
      "          [ 2.1357e-01,  2.2316e-01,  7.8880e-02,  2.4607e-02],\n",
      "          [ 1.7038e-01,  1.9608e-01,  1.7511e-01,  1.9339e-01],\n",
      "          [-1.7677e-03,  4.0403e-02, -1.0344e-01, -2.0739e-01]]]])\n",
      "conv.2.bias tensor([ 0.1775,  0.0405, -0.0317, -0.0865,  0.1731, -0.0934,  0.2160,  0.0354,\n",
      "         0.0384, -0.1517,  0.1953,  0.1349, -0.0356, -0.1180,  0.0225, -0.0344,\n",
      "        -0.0119, -0.1030,  0.0588, -0.1687, -0.2813,  0.0057, -0.0609,  0.0791,\n",
      "         0.1993, -0.1532,  0.1311,  0.1307,  0.0212,  0.5006,  0.1604, -0.1075,\n",
      "         0.1681, -0.1656, -0.0121,  0.1492, -0.1210,  0.3073, -0.2065, -0.0650,\n",
      "        -0.0618,  0.0032,  0.0067,  0.0468,  0.0881, -0.1498,  0.0684, -0.0102,\n",
      "         0.1889,  0.2905, -0.2051, -0.0408,  0.0501,  0.1612,  0.2104,  0.0521,\n",
      "        -0.1279,  0.0041,  0.0791,  0.0877, -0.1252, -0.0111, -0.0304,  0.0051])\n",
      "conv.4.weight tensor([[[[ 7.4676e-03,  1.1493e-01,  2.4163e-02],\n",
      "          [ 5.3383e-02,  3.4117e-02,  1.0961e-01],\n",
      "          [-1.4003e-02, -2.4954e-02,  9.2363e-05]],\n",
      "\n",
      "         [[-8.1394e-02, -1.1317e+00, -1.0300e+00],\n",
      "          [-3.4331e-01, -6.9131e-01, -2.5592e-01],\n",
      "          [-2.2338e-01, -1.8835e-01, -2.6712e-01]],\n",
      "\n",
      "         [[-7.6934e-02,  2.2812e-01,  2.2294e-01],\n",
      "          [ 3.0655e-01,  2.2551e-01,  2.6072e-01],\n",
      "          [-6.6600e-02,  4.1019e-01,  3.8171e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3109e-01, -8.6422e-02, -3.5958e-01],\n",
      "          [-4.1709e-01, -4.4836e-01, -5.1688e-01],\n",
      "          [-5.3752e-01, -5.5618e-01, -3.5923e-01]],\n",
      "\n",
      "         [[-1.0276e-03,  2.5259e-01,  2.6840e-01],\n",
      "          [ 2.9300e-01,  4.5080e-01,  3.5640e-01],\n",
      "          [ 2.1479e-01,  6.6054e-01,  2.5717e-01]],\n",
      "\n",
      "         [[-7.2207e-02,  1.4654e-01,  1.2303e-01],\n",
      "          [ 6.8371e-02,  2.3504e-01,  7.6170e-02],\n",
      "          [ 2.0075e-01,  3.2785e-01, -1.8545e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4690e-02, -1.4046e-02, -6.7050e-02],\n",
      "          [ 3.6358e-03, -7.0268e-02, -2.0296e-02],\n",
      "          [ 5.4692e-02,  1.1137e-01,  1.5680e-01]],\n",
      "\n",
      "         [[ 5.4937e-02, -2.2414e-03, -7.9466e-02],\n",
      "          [ 2.3971e-01, -9.4761e-02, -4.9278e-01],\n",
      "          [-4.2174e-02, -1.8650e-01, -4.7435e-02]],\n",
      "\n",
      "         [[-3.2672e-02,  1.4493e-02,  1.2073e-01],\n",
      "          [-8.6296e-02,  9.5562e-02, -2.7742e-01],\n",
      "          [ 1.6545e-01,  2.8596e-01,  3.0854e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.7403e-02, -4.9067e-01, -1.1803e-01],\n",
      "          [-4.8353e-02, -2.6905e-01,  5.5673e-02],\n",
      "          [ 4.3611e-01, -1.5012e-01,  1.5607e-01]],\n",
      "\n",
      "         [[-5.5769e-01,  4.3147e-02,  6.4159e-02],\n",
      "          [-1.4269e-01,  1.8998e-01, -3.7539e-02],\n",
      "          [ 1.0951e-01,  8.6237e-02,  1.3551e-01]],\n",
      "\n",
      "         [[-1.2171e-01,  1.0609e-01,  1.8607e-01],\n",
      "          [-4.1606e-02, -2.5453e-01,  2.8209e-02],\n",
      "          [-1.9187e-01,  4.1741e-02,  3.3695e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9399e-02, -5.1357e-02, -4.4046e-02],\n",
      "          [ 1.2203e-01, -8.6290e-03, -7.9872e-02],\n",
      "          [-2.5802e-02, -5.4790e-02,  5.8079e-03]],\n",
      "\n",
      "         [[ 2.9190e-01,  7.3584e-02, -2.5722e-02],\n",
      "          [ 1.4442e-01,  1.2627e-01, -4.3627e-02],\n",
      "          [ 5.2382e-02,  4.4474e-02,  1.7976e-02]],\n",
      "\n",
      "         [[ 5.3269e-01, -1.3762e-01, -6.2430e-02],\n",
      "          [-3.7620e-02, -8.0499e-02, -1.4665e-01],\n",
      "          [-2.4761e-03, -3.1072e-01,  4.5944e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6830e-01,  2.5303e-01,  3.5779e-02],\n",
      "          [ 2.7017e-02,  1.5342e-01,  9.5587e-02],\n",
      "          [ 5.2944e-02,  7.3927e-02,  1.1653e-01]],\n",
      "\n",
      "         [[-8.3509e-02,  4.0496e-01, -4.1392e-02],\n",
      "          [-3.1613e-01, -7.0970e-02, -2.9556e-01],\n",
      "          [-2.3133e-01, -8.8189e-01, -6.9264e-01]],\n",
      "\n",
      "         [[ 7.1740e-02,  2.9547e-01, -1.5055e-01],\n",
      "          [-2.1126e-01, -4.8691e-03, -2.6256e-01],\n",
      "          [ 6.1304e-02, -2.5125e-02,  9.5320e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 4.3115e-01,  2.7889e-01,  2.7378e-01],\n",
      "          [ 4.3634e-01,  3.0522e-01,  3.4896e-01],\n",
      "          [ 2.7919e-01,  2.5035e-01,  3.5084e-01]],\n",
      "\n",
      "         [[ 2.1453e-01,  2.6999e-01,  1.8007e-01],\n",
      "          [-6.6550e-02,  2.7113e-02, -9.6058e-02],\n",
      "          [-6.2999e-02, -2.4068e-02,  6.8942e-02]],\n",
      "\n",
      "         [[ 7.4366e-02, -1.5609e-01,  2.6404e-04],\n",
      "          [-1.5469e-02, -4.1912e-02,  1.8415e-01],\n",
      "          [ 1.5116e-03,  2.0873e-01,  3.3812e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-7.6601e-02,  1.1814e-01,  5.4062e-02],\n",
      "          [ 3.5810e-02,  2.1323e-01,  2.6456e-01],\n",
      "          [ 1.7246e-01,  9.9972e-02,  3.9376e-02]],\n",
      "\n",
      "         [[ 3.3191e-01,  4.2375e-02, -3.5723e-01],\n",
      "          [-1.5408e-01, -3.0679e-01,  2.4265e-02],\n",
      "          [ 1.0920e-01, -1.0819e-01,  2.2508e-03]],\n",
      "\n",
      "         [[-4.1818e-01, -1.5536e-01, -6.1239e-01],\n",
      "          [-5.8153e-01, -4.0722e-01, -6.6247e-01],\n",
      "          [-9.7492e-02, -1.3810e-01, -2.7569e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0965e-01,  3.9463e-01,  1.1670e-01],\n",
      "          [-4.0079e-03,  1.1403e-01, -2.9405e-02],\n",
      "          [ 1.4307e-01,  6.4347e-03,  6.1008e-02]],\n",
      "\n",
      "         [[ 2.5392e-01,  4.1849e-01,  6.3565e-02],\n",
      "          [ 1.3701e-01,  2.5860e-01,  1.3627e-01],\n",
      "          [ 1.3795e-01, -4.5274e-02, -7.3555e-03]],\n",
      "\n",
      "         [[-1.0072e-01, -2.3906e-01,  3.4527e-02],\n",
      "          [ 9.1333e-02,  5.1659e-02, -2.4219e-01],\n",
      "          [ 3.1957e-01, -5.8876e-01, -1.1410e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.3572e-01, -6.7398e-02,  4.3630e-01],\n",
      "          [ 2.8271e-01,  5.5966e-02,  1.6930e-01],\n",
      "          [ 6.0782e-01,  3.2416e-01,  1.2551e-01]],\n",
      "\n",
      "         [[ 3.5860e-01,  4.3654e-01,  4.3544e-01],\n",
      "          [-2.5702e-01, -5.1224e-01, -2.3755e-01],\n",
      "          [ 4.1587e-02, -1.2943e-01, -9.8693e-01]],\n",
      "\n",
      "         [[-1.5883e-01,  2.5340e-01,  2.7167e-01],\n",
      "          [-4.5235e-02, -7.5411e-04, -6.4206e-02],\n",
      "          [ 3.8810e-01,  1.2811e-01, -5.2013e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3625e-01, -1.9067e-01,  7.7161e-02],\n",
      "          [-4.1122e-01, -1.7430e-01,  1.6704e-01],\n",
      "          [-1.9538e-01, -9.4336e-03, -1.0544e-01]],\n",
      "\n",
      "         [[ 1.2388e-01, -1.0573e-02, -8.0283e-02],\n",
      "          [-5.4544e-02, -5.7805e-02, -1.2874e-02],\n",
      "          [ 2.2860e-02,  5.4817e-02, -1.7512e-02]],\n",
      "\n",
      "         [[ 3.4033e-01, -1.5532e-01, -1.2677e-01],\n",
      "          [-1.6189e-01,  1.2923e-01,  1.7444e-01],\n",
      "          [-1.2689e-01,  2.0303e-01, -2.7508e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3241e-01,  1.9531e-01, -1.6808e-01],\n",
      "          [ 2.0065e-01, -5.7733e-02,  4.0911e-01],\n",
      "          [ 2.9498e-01,  5.8692e-02,  2.0770e-02]],\n",
      "\n",
      "         [[ 8.1046e-02,  2.5603e-01,  4.6179e-01],\n",
      "          [-5.1360e-01, -2.2029e-01, -2.8379e-01],\n",
      "          [-2.4116e-01, -5.0848e-01, -3.6231e-01]],\n",
      "\n",
      "         [[ 4.1050e-02,  1.4062e-01,  2.6599e-01],\n",
      "          [ 8.8466e-02, -1.4993e-01, -1.9351e-02],\n",
      "          [-5.5415e-02, -3.7037e-02,  4.9725e-02]]]])\n",
      "conv.4.bias tensor([-0.0292,  0.1407,  0.1860,  0.0520,  0.1359, -0.1468,  0.2520,  0.1274,\n",
      "         0.0629,  0.1100,  0.0807,  0.2686,  0.0308, -0.2936, -0.3220,  0.1102,\n",
      "         0.3255,  0.2047, -0.2278, -0.0154, -0.0535,  0.0660, -0.0646,  0.2573,\n",
      "        -0.0625,  0.1801,  0.2367, -0.2491,  0.1227, -0.1389, -0.2653,  0.0812,\n",
      "         0.3511,  0.0711,  0.1076,  0.0179,  0.2360,  0.0062,  0.1354, -0.3322,\n",
      "        -0.0560, -0.0139, -0.1930,  0.0683, -0.0039,  0.3190,  0.2644,  0.2252,\n",
      "         0.1577,  0.0989,  0.1819, -0.0174, -0.0198,  0.0584,  0.1426,  0.1158,\n",
      "         0.1355, -0.0865,  0.0414,  0.2105,  0.1468,  0.4285,  0.0327, -0.0060])\n",
      "head.0.weight tensor([[-0.0045,  0.0073,  0.0117,  ...,  0.0009,  0.0009, -0.0232],\n",
      "        [-0.0369, -0.0085,  0.1963,  ...,  0.0086,  0.0646,  0.0574],\n",
      "        [-0.0115,  0.0080,  0.0058,  ...,  0.0098, -0.0224, -0.0164],\n",
      "        ...,\n",
      "        [-0.1529, -0.0278,  0.0395,  ...,  0.0295,  0.0462,  0.1019],\n",
      "        [ 0.0889, -0.0389,  0.0851,  ...,  0.0426, -0.0553, -0.0996],\n",
      "        [-0.2870,  0.0048,  0.1078,  ...,  0.1537,  0.1478,  0.2077]])\n",
      "head.0.bias tensor([-1.1088e-02,  5.4829e-02, -8.2273e-03, -1.7960e-02,  4.8147e-01,\n",
      "         1.0544e-02,  5.5657e-01, -1.6617e-02,  1.2777e-03,  1.1942e-01,\n",
      "        -2.2552e-02,  2.2074e-02, -1.2955e-02,  5.5890e-01,  3.0734e-01,\n",
      "         1.2063e-02, -2.3961e-02, -5.0495e-05,  6.0574e-03,  4.4548e-01,\n",
      "        -1.1269e-02,  3.2886e-01,  5.2749e-02, -1.3280e-01,  4.0063e-01,\n",
      "         4.0555e-01,  2.3004e-01, -6.7950e-03, -2.3875e-02, -3.9510e-02,\n",
      "         3.2951e-01, -1.7306e-02,  1.5533e-01,  1.4013e-03,  2.9393e-01,\n",
      "        -3.8739e-02, -8.2056e-03,  4.2705e-01, -1.9049e-02,  2.2084e-01,\n",
      "        -1.6947e-02,  7.2411e-01, -3.2804e-03, -1.5317e-02, -3.9885e-02,\n",
      "        -2.3550e-02,  2.6039e-03, -2.6594e-03, -3.4850e-02, -3.0364e-02,\n",
      "         1.9973e-03, -2.0611e-02,  3.7029e-02,  1.2652e-02,  5.6495e-01,\n",
      "        -2.2943e-02,  3.0077e-03,  4.7774e-03, -1.1434e-02, -9.0158e-03,\n",
      "        -1.9812e-01, -1.4586e-02,  5.4814e-03,  6.4062e-01,  1.4661e-01,\n",
      "        -1.1729e-02,  7.7164e-03,  7.0111e-03, -2.6212e-02,  6.5116e-01,\n",
      "         2.4997e-02,  1.9285e-01,  6.5588e-02,  3.7309e-01, -1.3826e-02,\n",
      "        -7.7961e-03,  1.4476e-01,  1.6835e-01,  4.7832e-01, -2.9829e-03,\n",
      "        -3.9766e-03,  4.7042e-03, -2.7632e-02,  9.6900e-02, -2.1120e-02,\n",
      "        -7.3398e-03,  6.0841e-03,  1.3624e-03,  1.8071e-01, -9.2828e-02,\n",
      "        -2.2072e-02,  2.0386e-01, -1.7727e-02,  3.7340e-01,  5.3201e-03,\n",
      "        -1.0271e-02,  1.5669e-01,  3.1280e-01,  7.7386e-02,  2.7923e-01,\n",
      "        -5.2387e-02, -1.3064e-02, -1.8975e-02,  3.6206e-01, -2.6514e-03,\n",
      "         2.6063e-01, -1.0439e-02,  2.1528e-01, -1.9404e-02, -1.7566e-02,\n",
      "         1.2950e-02,  2.2687e-01,  3.0457e-01, -1.6270e-03, -2.2773e-02,\n",
      "         2.1269e-01, -9.7610e-03,  2.0215e-01, -1.3346e-01,  1.8295e-01,\n",
      "         4.0907e-01,  4.1933e-03, -1.6398e-02, -1.1069e-03, -6.9766e-03,\n",
      "         5.0662e-01,  5.5805e-01, -3.3665e-02,  8.0536e-02,  3.9004e-01,\n",
      "         6.0886e-01, -1.1050e-02,  8.2731e-02, -1.9240e-02,  1.8579e-01,\n",
      "         9.7281e-02,  8.3693e-02, -1.1842e-02, -1.3959e-03,  2.5505e-03,\n",
      "        -4.0606e-03,  1.2948e-02, -2.1823e-02,  5.9846e-01,  1.3825e-02,\n",
      "        -1.1921e-02, -5.9700e-02,  3.8181e-01, -2.6691e-03,  5.2965e-03,\n",
      "         5.3127e-03,  1.6670e-01,  1.8595e-03, -7.3176e-04, -1.7833e-02,\n",
      "         3.6562e-01, -3.2105e-02,  2.7997e-01,  3.6359e-01,  6.2530e-01,\n",
      "         6.2456e-01, -4.9587e-02, -1.3434e-02,  1.9091e-01, -2.0260e-02,\n",
      "        -1.3969e-02, -1.1361e-02, -2.9583e-02,  4.9683e-02, -2.4111e-02,\n",
      "         7.2387e-03,  6.9688e-01, -2.0277e-01, -1.9823e-03,  1.3373e-02,\n",
      "        -1.5128e-02, -1.2365e-02,  2.2163e-01, -2.0521e-02,  1.1535e-02,\n",
      "        -1.3629e-02, -7.6874e-04,  3.6438e-01,  5.3449e-01, -9.7464e-02,\n",
      "         3.0397e-01, -3.1039e-02,  3.1044e-01, -1.2096e-01, -2.2408e-02,\n",
      "         1.2036e-02, -1.6892e-02,  6.1090e-01, -7.3055e-03,  7.8990e-03,\n",
      "         2.9433e-02, -5.4250e-03, -1.3499e-02,  9.1152e-02,  1.0252e-04,\n",
      "        -1.4282e-02, -1.5565e-02, -9.4581e-03, -1.1716e-02, -8.6749e-04,\n",
      "         8.4369e-02,  2.7151e-01, -2.0995e-02,  2.9645e-01, -5.5791e-03,\n",
      "        -9.8764e-03, -9.0936e-03, -2.0727e-01, -2.0691e-02, -2.8090e-02,\n",
      "        -1.8532e-02,  2.4643e-02,  2.1594e-03, -1.5018e-02,  1.8909e-03,\n",
      "         6.9655e-03,  6.0629e-01,  3.6859e-01, -1.8099e-02,  4.5074e-04,\n",
      "         9.7860e-02, -4.4849e-02,  1.0739e-01,  4.2223e-01,  9.8973e-03,\n",
      "         6.5441e-01,  5.2833e-01,  4.6296e-01,  1.2900e-02, -1.2034e-02,\n",
      "        -1.3456e-03,  6.0327e-01, -1.6506e-02,  1.4496e-02, -1.8956e-02,\n",
      "         5.5817e-02,  2.3312e-01,  9.5193e-03,  4.3079e-01,  2.8301e-01,\n",
      "         6.2906e-01, -9.7844e-03,  7.2058e-01,  4.8892e-01, -4.5468e-01,\n",
      "        -1.1530e-02,  3.7830e-01, -1.6437e-02,  4.4188e-01, -6.6846e-03,\n",
      "         9.8256e-03, -1.5891e-02,  4.2673e-03, -1.8826e-02, -3.1782e-02,\n",
      "        -1.1176e-02, -2.1449e-02,  3.2816e-01, -9.5291e-02, -1.3930e-02,\n",
      "         1.5483e-01,  9.6968e-03, -1.2803e-02,  4.7660e-01, -1.8304e-02,\n",
      "         5.0809e-03, -2.2372e-02,  5.4899e-02,  3.8083e-03, -9.6371e-03,\n",
      "        -1.4600e-02,  5.0888e-01,  3.2500e-01, -8.5845e-03,  1.5323e-02,\n",
      "        -3.4056e-03,  4.8600e-01,  1.0020e-02,  5.7945e-03,  1.2249e-02,\n",
      "        -1.2918e-01, -2.6578e-03,  1.8908e-01,  6.7964e-01,  2.6886e-01,\n",
      "         5.6624e-04, -1.8622e-02, -1.0477e-02, -1.6929e-02,  1.0959e-02,\n",
      "        -2.0414e-03,  2.5973e-03,  3.3134e-01, -2.2514e-01,  1.4609e-02,\n",
      "        -2.1663e-02, -3.2140e-02, -9.5049e-03,  2.9751e-02, -1.3374e-02,\n",
      "         5.0510e-01,  4.2110e-02, -1.4878e-02, -4.6154e-02, -1.4224e-02,\n",
      "        -9.7909e-03,  7.0499e-03, -2.1617e-02,  4.1168e-01,  1.0255e-01,\n",
      "         1.2659e-02,  2.0315e-01, -2.3483e-03, -2.3499e-02,  7.5315e-03,\n",
      "         5.2451e-01, -1.8720e-02, -1.5019e-02,  4.6528e-02,  1.3750e-01,\n",
      "         6.7969e-03, -1.8652e-02,  1.1134e-01, -5.1240e-03, -2.2433e-02,\n",
      "         1.2454e-01,  3.1367e-01, -8.0752e-02,  4.6676e-01,  4.4040e-01,\n",
      "         3.6116e-01, -8.2152e-03,  1.9815e-03,  2.1786e-01,  3.7455e-03,\n",
      "        -2.8978e-02,  3.4106e-01,  2.2317e-01,  4.7649e-01, -9.8917e-03,\n",
      "         4.8050e-04,  5.7494e-03, -7.3200e-03, -2.1322e-02, -1.2255e-02,\n",
      "         1.0958e-02,  1.0826e-02, -1.0927e-03,  6.8700e-01,  7.8428e-01,\n",
      "         1.0204e-01, -8.6570e-04, -1.7518e-02,  6.0830e-01,  4.5775e-01,\n",
      "        -5.8586e-03, -6.3915e-03,  5.7133e-02,  2.8777e-01,  4.7496e-01,\n",
      "        -1.4915e-02, -1.1764e-02,  5.3864e-01, -2.9606e-02, -5.3224e-03,\n",
      "        -1.2300e-02, -2.9094e-02,  1.5452e-01, -8.5084e-03,  1.4058e-01,\n",
      "         1.0050e-01, -2.1124e-02,  1.6553e-01, -1.5198e-02,  2.8029e-01,\n",
      "         5.5401e-02,  3.1918e-03,  2.5982e-01,  2.2597e-01, -5.1218e-03,\n",
      "         4.1206e-01,  6.0922e-02,  4.6272e-01,  2.4574e-01,  9.6077e-02,\n",
      "         2.7016e-03,  1.3125e-01,  2.7951e-01, -1.0594e-02, -1.8228e-02,\n",
      "         7.0327e-01, -1.5082e-02, -3.7098e-03, -5.2937e-03,  1.1129e-01,\n",
      "         5.0961e-02, -1.5651e-02, -1.7149e-03,  1.7092e-01,  6.2681e-01,\n",
      "         2.1705e-01,  1.8947e-01,  1.6221e-01,  6.2020e-01,  2.9880e-01,\n",
      "         3.3080e-01,  4.3920e-01, -2.6253e-02,  5.2967e-01,  4.0836e-03,\n",
      "         1.1578e-02,  5.4863e-03, -1.6190e-03,  1.2494e-02,  2.1649e-01,\n",
      "        -1.1731e-02,  1.2190e-02, -1.6004e-02,  4.5509e-02,  7.8324e-02,\n",
      "         5.4890e-01,  6.5489e-01,  1.3211e-02, -1.0753e-02,  3.6935e-01,\n",
      "         6.1716e-03, -1.8478e-02, -1.6060e-02,  5.9700e-01, -2.2688e-02,\n",
      "         5.8837e-01,  3.4740e-01, -2.1620e-03,  3.0837e-01,  1.4568e-01,\n",
      "        -2.1298e-02, -5.8010e-03,  1.4101e-03,  1.3266e-01,  2.0413e-01,\n",
      "         4.1053e-02, -7.6364e-03, -8.0039e-02,  3.5716e-01, -1.0666e-02,\n",
      "        -2.0552e-02,  2.6134e-02,  2.8721e-01,  6.5265e-01,  1.3588e-01,\n",
      "         6.0954e-01, -1.0825e-02, -1.8298e-02,  1.1218e-03,  4.9119e-03,\n",
      "        -1.4784e-02,  4.3224e-01,  1.9658e-01,  2.5814e-01, -4.5141e-03,\n",
      "         9.9852e-03,  5.4603e-01,  2.1247e-01, -1.6758e-02,  2.5644e-01,\n",
      "        -1.3602e-02, -1.5202e-02, -1.3601e-03,  3.8844e-02,  6.6685e-03,\n",
      "         4.2461e-01,  5.7618e-02, -3.0833e-02,  1.3842e-04, -6.7648e-04,\n",
      "        -3.8100e-03,  2.6154e-02,  6.5422e-01,  2.7993e-01, -2.4929e-05,\n",
      "         8.3025e-02,  5.6357e-01, -1.6011e-04,  5.2689e-01,  5.2371e-03,\n",
      "         5.4633e-01,  4.1999e-01,  3.1475e-01, -1.0438e-02,  3.1624e-02,\n",
      "         6.1204e-01,  4.8396e-03,  9.3020e-02,  3.2498e-03,  3.0966e-01,\n",
      "         6.7347e-03, -1.7631e-02,  4.1502e-01, -1.8602e-03,  4.5190e-03,\n",
      "         1.2400e-02,  5.2752e-01,  7.2082e-02, -1.0101e-02,  4.2046e-01,\n",
      "        -3.1158e-04,  4.1027e-01])\n",
      "head.2.weight tensor([[ 0.0242,  0.2556,  0.0296,  ..., -0.1859, -0.1983,  0.6331],\n",
      "        [ 0.0354, -1.2310, -0.0027,  ...,  0.0407,  0.0996,  0.5480],\n",
      "        [ 0.0067,  0.8317,  0.0199,  ...,  0.0267,  0.3444,  0.6105],\n",
      "        [-0.0095,  0.1552, -0.0055,  ...,  0.2108, -0.5154,  0.7952],\n",
      "        [-0.0343,  0.6002, -0.0214,  ..., -0.1484,  0.3752,  0.6717],\n",
      "        [-0.0021, -0.3537, -0.0424,  ...,  0.0464, -1.0643,  0.6731]])\n",
      "head.2.bias tensor([0.5338, 0.3510, 0.4662, 0.4266, 0.3781, 0.4182])\n"
     ]
    }
   ],
   "source": [
    "for name, param in rl_net.net.named_parameters(): print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[100.0, 110.0, 130.0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env=\"DemonAttack-v0\"\n",
    "rl_net.run_n_episodes(env=rl_net.env,n_epsiodes=3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
